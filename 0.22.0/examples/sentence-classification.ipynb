{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentence classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial we will try to predict whether an SMS is a spam or not. To train our model, we will use the `SMSSpam` dataset. This dataset is unbalanced, there is only 13.4% spam. Let's look at the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-24T18:23:24.044784Z",
     "iopub.status.busy": "2024-11-24T18:23:24.044591Z",
     "iopub.status.idle": "2024-11-24T18:23:25.027553Z",
     "shell.execute_reply": "2024-11-24T18:23:25.026896Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "SMS Spam Collection dataset.\n",
       "\n",
       "The data contains \u001b[1;36m5\u001b[0m,\u001b[1;36m574\u001b[0m items and \u001b[1;36m1\u001b[0m feature \u001b[1m(\u001b[0mi.e. SMS body\u001b[1m)\u001b[0m. Spam messages represent\n",
       "\u001b[1;36m13.4\u001b[0m% of the dataset. The goal is to predict whether an SMS is a spam or not.\n",
       "\n",
       "      Name  SMSSpam                                                                              \n",
       "      Task  Binary classification                                                                \n",
       "   Samples  \u001b[1;36m5\u001b[0m,\u001b[1;36m574\u001b[0m                                                                                \n",
       "  Features  \u001b[1;36m1\u001b[0m                                                                                    \n",
       "    Sparse  \u001b[3;91mFalse\u001b[0m                                                                                \n",
       "      Path  \u001b[35m/home/runner/river_data/SMSSpam/\u001b[0m\u001b[95mSMSSpamCollection\u001b[0m                                    \n",
       "       URL  \u001b[4;94mhttps://archive.ics.uci.edu/ml/machine-learning-databases/00228/smsspamcollection.zip\u001b[0m\n",
       "      Size  \u001b[1;36m466.71\u001b[0m KiB                                                                           \n",
       "Downloaded  \u001b[3;92mTrue\u001b[0m                                                                                 "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from river import datasets\n",
    "\n",
    "datasets.SMSSpam()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-24T18:23:25.029493Z",
     "iopub.status.busy": "2024-11-24T18:23:25.029222Z",
     "iopub.status.idle": "2024-11-24T18:23:25.033717Z",
     "shell.execute_reply": "2024-11-24T18:23:25.033165Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'body': 'Go until jurong point, crazy.. Available only in bugis n great world '\n",
      "         'la e buffet... Cine there got amore wat...\\n'}\n",
      "Spam: False\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "X_y = datasets.SMSSpam()\n",
    "\n",
    "for x, y in X_y:\n",
    "    pprint(x)\n",
    "    print(f'Spam: {y}')\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by building a simple model like a Naive Bayes classifier. We will first preprocess the sentences with a TF-IDF transform that our model can consume. Then, we will measure the accuracy of our model with the AUC metric. This is the right metric to use when the classes are not balanced. In addition, the Naive Bayes models can perform very well on unbalanced datasets and can be used for both binary and multi-class classification problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-24T18:23:25.035618Z",
     "iopub.status.busy": "2024-11-24T18:23:25.035290Z",
     "iopub.status.idle": "2024-11-24T18:23:54.578908Z",
     "shell.execute_reply": "2024-11-24T18:23:54.578366Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "ROCAUC: \u001b[1;36m93.00\u001b[0m%"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from river import feature_extraction\n",
    "from river import naive_bayes\n",
    "from river import metrics\n",
    "\n",
    "X_y = datasets.SMSSpam()\n",
    "\n",
    "model = (\n",
    "    feature_extraction.TFIDF(on='body') | \n",
    "    naive_bayes.BernoulliNB(alpha=0)\n",
    ")\n",
    "\n",
    "metric = metrics.ROCAUC()\n",
    "cm = metrics.ConfusionMatrix()\n",
    "\n",
    "for x, y in X_y:\n",
    "    \n",
    "    y_pred = model.predict_one(x)\n",
    "    \n",
    "    if y_pred is not None:\n",
    "        metric.update(y_pred=y_pred, y_true=y)\n",
    "        cm.update(y_pred=y_pred, y_true=y)\n",
    "    \n",
    "    model.learn_one(x, y)\n",
    "    \n",
    "metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The confusion matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-24T18:23:54.581017Z",
     "iopub.status.busy": "2024-11-24T18:23:54.580629Z",
     "iopub.status.idle": "2024-11-24T18:23:54.585999Z",
     "shell.execute_reply": "2024-11-24T18:23:54.585547Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "        \u001b[3;91mFalse\u001b[0m   \u001b[3;92mTrue\u001b[0m  \n",
       "\u001b[3;91mFalse\u001b[0m   \u001b[1;36m4\u001b[0m,\u001b[1;36m809\u001b[0m     \u001b[1;36m17\u001b[0m  \n",
       " \u001b[3;92mTrue\u001b[0m     \u001b[1;36m102\u001b[0m    \u001b[1;36m645\u001b[0m  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results are quite good with this first model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we are working with an imbalanced dataset, we can use the `imblearn` module to rebalance the classes of our dataset. For more information about the `imblearn` module, you can find a dedicated tutorial [here](../imbalanced-learning)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-24T18:23:54.587885Z",
     "iopub.status.busy": "2024-11-24T18:23:54.587693Z",
     "iopub.status.idle": "2024-11-24T18:24:10.802296Z",
     "shell.execute_reply": "2024-11-24T18:24:10.801781Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "ROCAUC: \u001b[1;36m94.61\u001b[0m%"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from river import imblearn\n",
    "\n",
    "X_y = datasets.SMSSpam()\n",
    "\n",
    "model = (\n",
    "    feature_extraction.TFIDF(on='body') | \n",
    "    imblearn.RandomUnderSampler(\n",
    "        classifier=naive_bayes.BernoulliNB(alpha=0),\n",
    "        desired_dist={0: .5, 1: .5},\n",
    "        seed=42\n",
    "    )\n",
    ")\n",
    "\n",
    "metric = metrics.ROCAUC()\n",
    "cm = metrics.ConfusionMatrix()\n",
    "\n",
    "for x, y in X_y:\n",
    "    \n",
    "    y_pred = model.predict_one(x)\n",
    "    \n",
    "    if y_pred is not None:\n",
    "        metric.update(y_pred=y_pred, y_true=y)\n",
    "        cm.update(y_pred=y_pred, y_true=y)\n",
    "    \n",
    "    model.learn_one(x, y)\n",
    "    \n",
    "metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `imblearn` module improved our results. Not bad! We can visualize the pipeline to understand how the data is processed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The confusion matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-24T18:24:10.804205Z",
     "iopub.status.busy": "2024-11-24T18:24:10.804019Z",
     "iopub.status.idle": "2024-11-24T18:24:10.809449Z",
     "shell.execute_reply": "2024-11-24T18:24:10.808899Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "        \u001b[3;91mFalse\u001b[0m   \u001b[3;92mTrue\u001b[0m  \n",
       "\u001b[3;91mFalse\u001b[0m   \u001b[1;36m4\u001b[0m,\u001b[1;36m570\u001b[0m    \u001b[1;36m255\u001b[0m  \n",
       " \u001b[3;92mTrue\u001b[0m      \u001b[1;36m41\u001b[0m    \u001b[1;36m706\u001b[0m  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-24T18:24:10.811415Z",
     "iopub.status.busy": "2024-11-24T18:24:10.810977Z",
     "iopub.status.idle": "2024-11-24T18:24:10.821259Z",
     "shell.execute_reply": "2024-11-24T18:24:10.820680Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div><div class=\"river-component river-pipeline\"><details class=\"river-component river-estimator\"><summary class=\"river-summary\"><pre class=\"river-estimator-name\">TFIDF</pre></summary><code class=\"river-estimator-params\">TFIDF (\n",
       "  normalize=True\n",
       "  on=\"body\"\n",
       "  strip_accents=True\n",
       "  lowercase=True\n",
       "  preprocessor=None\n",
       "  stop_words=None\n",
       "  tokenizer_pattern=\"(?u)\\b\\w[\\w\\-]+\\b\"\n",
       "  tokenizer=None\n",
       "  ngram_range=(1, 1)\n",
       ")\n",
       "</code></details><div class=\"river-component river-wrapper\"><details class=\"river-details\"><summary class=\"river-summary\"><pre class=\"river-estimator-name\">RandomUnderSampler</pre></summary><code class=\"river-estimator-params\">RandomUnderSampler (\n",
       "  classifier=BernoulliNB (\n",
       "    alpha=0\n",
       "    true_threshold=0.\n",
       "  )\n",
       "  desired_dist={0: 0.5, 1: 0.5}\n",
       "  seed=42\n",
       ")\n",
       "</code></details><details class=\"river-component river-estimator\"><summary class=\"river-summary\"><pre class=\"river-estimator-name\">BernoulliNB</pre></summary><code class=\"river-estimator-params\">BernoulliNB (\n",
       "  alpha=0\n",
       "  true_threshold=0.\n",
       ")\n",
       "</code></details></div></div><style scoped>\n",
       ".river-estimator {\n",
       "    padding: 1em;\n",
       "    border-style: solid;\n",
       "    background: white;\n",
       "    max-width: max-content;\n",
       "}\n",
       "\n",
       ".river-pipeline {\n",
       "    display: flex;\n",
       "    flex-direction: column;\n",
       "    align-items: center;\n",
       "    background: linear-gradient(#000, #000) no-repeat center / 1.5px 100%;\n",
       "}\n",
       "\n",
       ".river-union {\n",
       "    display: flex;\n",
       "    flex-direction: row;\n",
       "    align-items: center;\n",
       "    justify-content: center;\n",
       "    padding: 1em;\n",
       "    border-style: solid;\n",
       "    background: white;\n",
       "}\n",
       "\n",
       ".river-wrapper {\n",
       "    display: flex;\n",
       "    flex-direction: column;\n",
       "    align-items: center;\n",
       "    justify-content: center;\n",
       "    padding: 1em;\n",
       "    border-style: solid;\n",
       "    background: white;\n",
       "}\n",
       "\n",
       ".river-wrapper > .river-estimator {\n",
       "    margin-top: 1em;\n",
       "}\n",
       "\n",
       "/* Vertical spacing between steps */\n",
       "\n",
       ".river-component + .river-component {\n",
       "    margin-top: 2em;\n",
       "}\n",
       "\n",
       ".river-union > .river-estimator {\n",
       "    margin-top: 0;\n",
       "}\n",
       "\n",
       ".river-union > .river-component {\n",
       "    margin-top: 0;\n",
       "}\n",
       "\n",
       ".river-union > .pipeline {\n",
       "    margin-top: 0;\n",
       "}\n",
       "\n",
       "/* Spacing within a union of estimators */\n",
       "\n",
       ".river-union > .river-component + .river-component {\n",
       "    margin-left: 1em;\n",
       "}\n",
       "\n",
       "/* Typography */\n",
       "\n",
       ".river-estimator-params {\n",
       "    display: block;\n",
       "    white-space: pre-wrap;\n",
       "    font-size: 110%;\n",
       "    margin-top: 1em;\n",
       "}\n",
       "\n",
       ".river-estimator > .river-estimator-params,\n",
       ".river-wrapper > .river-details > river-estimator-params {\n",
       "    background-color: white !important;\n",
       "}\n",
       "\n",
       ".river-wrapper > .river-details {\n",
       "    margin-bottom: 1em;\n",
       "}\n",
       "\n",
       ".river-estimator-name {\n",
       "    display: inline;\n",
       "    margin: 0;\n",
       "    font-size: 110%;\n",
       "}\n",
       "\n",
       "/* Toggle */\n",
       "\n",
       ".river-summary {\n",
       "    display: flex;\n",
       "    align-items:center;\n",
       "    cursor: pointer;\n",
       "}\n",
       "\n",
       ".river-summary > div {\n",
       "    width: 100%;\n",
       "}\n",
       "</style></div>"
      ],
      "text/plain": [
       "\n",
       "Pipeline \u001b[1m(\u001b[0m\n",
       "  TFIDF \u001b[1m(\u001b[0m\n",
       "    \u001b[33mnormalize\u001b[0m=\u001b[3;92mTrue\u001b[0m\n",
       "    \u001b[33mon\u001b[0m=\u001b[32m\"body\"\u001b[0m\n",
       "    \u001b[33mstrip_accents\u001b[0m=\u001b[3;92mTrue\u001b[0m\n",
       "    \u001b[33mlowercase\u001b[0m=\u001b[3;92mTrue\u001b[0m\n",
       "    \u001b[33mpreprocessor\u001b[0m=\u001b[3;35mNone\u001b[0m\n",
       "    \u001b[33mstop_words\u001b[0m=\u001b[3;35mNone\u001b[0m\n",
       "    \u001b[33mtokenizer_pattern\u001b[0m=\u001b[32m\"\u001b[0m\u001b[32m(\u001b[0m\u001b[32m?u\u001b[0m\u001b[32m)\u001b[0m\u001b[32m\\b\\w\u001b[0m\u001b[32m[\u001b[0m\u001b[32m\\w\\-\u001b[0m\u001b[32m]\u001b[0m\u001b[32m+\\b\"\u001b[0m\n",
       "    \u001b[33mtokenizer\u001b[0m=\u001b[3;35mNone\u001b[0m\n",
       "    \u001b[33mngram_range\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m\n",
       "  \u001b[1m)\u001b[0m,\n",
       "  RandomUnderSampler \u001b[1m(\u001b[0m\n",
       "    \u001b[33mclassifier\u001b[0m=\u001b[35mBernoulliNB\u001b[0m \u001b[1m(\u001b[0m\n",
       "      \u001b[33malpha\u001b[0m=\u001b[1;36m0\u001b[0m\n",
       "      \u001b[33mtrue_threshold\u001b[0m=\u001b[1;36m0\u001b[0m.\n",
       "    \u001b[1m)\u001b[0m\n",
       "    \u001b[33mdesired_dist\u001b[0m=\u001b[1m{\u001b[0m\u001b[1;36m0\u001b[0m: \u001b[1;36m0.5\u001b[0m, \u001b[1;36m1\u001b[0m: \u001b[1;36m0.5\u001b[0m\u001b[1m}\u001b[0m\n",
       "    \u001b[33mseed\u001b[0m=\u001b[1;36m42\u001b[0m\n",
       "  \u001b[1m)\u001b[0m\n",
       "\u001b[1m)\u001b[0m"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's try to use logistic regression to classify messages. We will use different tips to make my model perform better. As in the previous example, we rebalance the classes of our dataset. The logistics regression will be fed from a TF-IDF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-24T18:24:10.823116Z",
     "iopub.status.busy": "2024-11-24T18:24:10.822935Z",
     "iopub.status.idle": "2024-11-24T18:24:11.779644Z",
     "shell.execute_reply": "2024-11-24T18:24:11.779107Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "ROCAUC: \u001b[1;36m93.80\u001b[0m%"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from river import linear_model\n",
    "from river import optim\n",
    "from river import preprocessing\n",
    "\n",
    "X_y = datasets.SMSSpam()\n",
    "\n",
    "model = (\n",
    "    feature_extraction.TFIDF(on='body') | \n",
    "    preprocessing.Normalizer() | \n",
    "    imblearn.RandomUnderSampler(\n",
    "        classifier=linear_model.LogisticRegression(\n",
    "            optimizer=optim.SGD(.9), \n",
    "            loss=optim.losses.Log()\n",
    "        ),\n",
    "        desired_dist={0: .5, 1: .5},\n",
    "        seed=42\n",
    "    )\n",
    ")\n",
    "\n",
    "metric = metrics.ROCAUC()\n",
    "cm = metrics.ConfusionMatrix()\n",
    "\n",
    "for x, y in X_y:\n",
    "    \n",
    "    y_pred = model.predict_one(x)\n",
    "\n",
    "    metric.update(y_pred=y_pred, y_true=y)\n",
    "    cm.update(y_pred=y_pred, y_true=y)\n",
    "    \n",
    "    model.learn_one(x, y)\n",
    "    \n",
    "metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The confusion matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-24T18:24:11.781756Z",
     "iopub.status.busy": "2024-11-24T18:24:11.781288Z",
     "iopub.status.idle": "2024-11-24T18:24:11.786474Z",
     "shell.execute_reply": "2024-11-24T18:24:11.786025Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "        \u001b[3;91mFalse\u001b[0m   \u001b[3;92mTrue\u001b[0m  \n",
       "\u001b[3;91mFalse\u001b[0m   \u001b[1;36m4\u001b[0m,\u001b[1;36m584\u001b[0m    \u001b[1;36m243\u001b[0m  \n",
       " \u001b[3;92mTrue\u001b[0m      \u001b[1;36m55\u001b[0m    \u001b[1;36m692\u001b[0m  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-24T18:24:11.788414Z",
     "iopub.status.busy": "2024-11-24T18:24:11.787940Z",
     "iopub.status.idle": "2024-11-24T18:24:11.796426Z",
     "shell.execute_reply": "2024-11-24T18:24:11.795980Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div><div class=\"river-component river-pipeline\"><details class=\"river-component river-estimator\"><summary class=\"river-summary\"><pre class=\"river-estimator-name\">TFIDF</pre></summary><code class=\"river-estimator-params\">TFIDF (\n",
       "  normalize=True\n",
       "  on=\"body\"\n",
       "  strip_accents=True\n",
       "  lowercase=True\n",
       "  preprocessor=None\n",
       "  stop_words=None\n",
       "  tokenizer_pattern=\"(?u)\\b\\w[\\w\\-]+\\b\"\n",
       "  tokenizer=None\n",
       "  ngram_range=(1, 1)\n",
       ")\n",
       "</code></details><details class=\"river-component river-estimator\"><summary class=\"river-summary\"><pre class=\"river-estimator-name\">Normalizer</pre></summary><code class=\"river-estimator-params\">Normalizer (\n",
       "  order=2\n",
       ")\n",
       "</code></details><div class=\"river-component river-wrapper\"><details class=\"river-details\"><summary class=\"river-summary\"><pre class=\"river-estimator-name\">RandomUnderSampler</pre></summary><code class=\"river-estimator-params\">RandomUnderSampler (\n",
       "  classifier=LogisticRegression (\n",
       "    optimizer=SGD (\n",
       "      lr=Constant (\n",
       "        learning_rate=0.9\n",
       "      )\n",
       "    )\n",
       "    loss=Log (\n",
       "      weight_pos=1.\n",
       "      weight_neg=1.\n",
       "    )\n",
       "    l2=0.\n",
       "    l1=0.\n",
       "    intercept_init=0.\n",
       "    intercept_lr=Constant (\n",
       "      learning_rate=0.01\n",
       "    )\n",
       "    clip_gradient=1e+12\n",
       "    initializer=Zeros ()\n",
       "  )\n",
       "  desired_dist={0: 0.5, 1: 0.5}\n",
       "  seed=42\n",
       ")\n",
       "</code></details><details class=\"river-component river-estimator\"><summary class=\"river-summary\"><pre class=\"river-estimator-name\">LogisticRegression</pre></summary><code class=\"river-estimator-params\">LogisticRegression (\n",
       "  optimizer=SGD (\n",
       "    lr=Constant (\n",
       "      learning_rate=0.9\n",
       "    )\n",
       "  )\n",
       "  loss=Log (\n",
       "    weight_pos=1.\n",
       "    weight_neg=1.\n",
       "  )\n",
       "  l2=0.\n",
       "  l1=0.\n",
       "  intercept_init=0.\n",
       "  intercept_lr=Constant (\n",
       "    learning_rate=0.01\n",
       "  )\n",
       "  clip_gradient=1e+12\n",
       "  initializer=Zeros ()\n",
       ")\n",
       "</code></details></div></div><style scoped>\n",
       ".river-estimator {\n",
       "    padding: 1em;\n",
       "    border-style: solid;\n",
       "    background: white;\n",
       "    max-width: max-content;\n",
       "}\n",
       "\n",
       ".river-pipeline {\n",
       "    display: flex;\n",
       "    flex-direction: column;\n",
       "    align-items: center;\n",
       "    background: linear-gradient(#000, #000) no-repeat center / 1.5px 100%;\n",
       "}\n",
       "\n",
       ".river-union {\n",
       "    display: flex;\n",
       "    flex-direction: row;\n",
       "    align-items: center;\n",
       "    justify-content: center;\n",
       "    padding: 1em;\n",
       "    border-style: solid;\n",
       "    background: white;\n",
       "}\n",
       "\n",
       ".river-wrapper {\n",
       "    display: flex;\n",
       "    flex-direction: column;\n",
       "    align-items: center;\n",
       "    justify-content: center;\n",
       "    padding: 1em;\n",
       "    border-style: solid;\n",
       "    background: white;\n",
       "}\n",
       "\n",
       ".river-wrapper > .river-estimator {\n",
       "    margin-top: 1em;\n",
       "}\n",
       "\n",
       "/* Vertical spacing between steps */\n",
       "\n",
       ".river-component + .river-component {\n",
       "    margin-top: 2em;\n",
       "}\n",
       "\n",
       ".river-union > .river-estimator {\n",
       "    margin-top: 0;\n",
       "}\n",
       "\n",
       ".river-union > .river-component {\n",
       "    margin-top: 0;\n",
       "}\n",
       "\n",
       ".river-union > .pipeline {\n",
       "    margin-top: 0;\n",
       "}\n",
       "\n",
       "/* Spacing within a union of estimators */\n",
       "\n",
       ".river-union > .river-component + .river-component {\n",
       "    margin-left: 1em;\n",
       "}\n",
       "\n",
       "/* Typography */\n",
       "\n",
       ".river-estimator-params {\n",
       "    display: block;\n",
       "    white-space: pre-wrap;\n",
       "    font-size: 110%;\n",
       "    margin-top: 1em;\n",
       "}\n",
       "\n",
       ".river-estimator > .river-estimator-params,\n",
       ".river-wrapper > .river-details > river-estimator-params {\n",
       "    background-color: white !important;\n",
       "}\n",
       "\n",
       ".river-wrapper > .river-details {\n",
       "    margin-bottom: 1em;\n",
       "}\n",
       "\n",
       ".river-estimator-name {\n",
       "    display: inline;\n",
       "    margin: 0;\n",
       "    font-size: 110%;\n",
       "}\n",
       "\n",
       "/* Toggle */\n",
       "\n",
       ".river-summary {\n",
       "    display: flex;\n",
       "    align-items:center;\n",
       "    cursor: pointer;\n",
       "}\n",
       "\n",
       ".river-summary > div {\n",
       "    width: 100%;\n",
       "}\n",
       "</style></div>"
      ],
      "text/plain": [
       "\n",
       "Pipeline \u001b[1m(\u001b[0m\n",
       "  TFIDF \u001b[1m(\u001b[0m\n",
       "    \u001b[33mnormalize\u001b[0m=\u001b[3;92mTrue\u001b[0m\n",
       "    \u001b[33mon\u001b[0m=\u001b[32m\"body\"\u001b[0m\n",
       "    \u001b[33mstrip_accents\u001b[0m=\u001b[3;92mTrue\u001b[0m\n",
       "    \u001b[33mlowercase\u001b[0m=\u001b[3;92mTrue\u001b[0m\n",
       "    \u001b[33mpreprocessor\u001b[0m=\u001b[3;35mNone\u001b[0m\n",
       "    \u001b[33mstop_words\u001b[0m=\u001b[3;35mNone\u001b[0m\n",
       "    \u001b[33mtokenizer_pattern\u001b[0m=\u001b[32m\"\u001b[0m\u001b[32m(\u001b[0m\u001b[32m?u\u001b[0m\u001b[32m)\u001b[0m\u001b[32m\\b\\w\u001b[0m\u001b[32m[\u001b[0m\u001b[32m\\w\\-\u001b[0m\u001b[32m]\u001b[0m\u001b[32m+\\b\"\u001b[0m\n",
       "    \u001b[33mtokenizer\u001b[0m=\u001b[3;35mNone\u001b[0m\n",
       "    \u001b[33mngram_range\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m\n",
       "  \u001b[1m)\u001b[0m,\n",
       "  Normalizer \u001b[1m(\u001b[0m\n",
       "    \u001b[33morder\u001b[0m=\u001b[1;36m2\u001b[0m\n",
       "  \u001b[1m)\u001b[0m,\n",
       "  RandomUnderSampler \u001b[1m(\u001b[0m\n",
       "    \u001b[33mclassifier\u001b[0m=\u001b[35mLogisticRegression\u001b[0m \u001b[1m(\u001b[0m\n",
       "      \u001b[33moptimizer\u001b[0m=\u001b[35mSGD\u001b[0m \u001b[1m(\u001b[0m\n",
       "        \u001b[33mlr\u001b[0m=\u001b[35mConstant\u001b[0m \u001b[1m(\u001b[0m\n",
       "          \u001b[33mlearning_rate\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.9\u001b[0m\n",
       "        \u001b[1m)\u001b[0m\n",
       "      \u001b[1m)\u001b[0m\n",
       "      \u001b[33mloss\u001b[0m=\u001b[35mLog\u001b[0m \u001b[1m(\u001b[0m\n",
       "        \u001b[33mweight_pos\u001b[0m=\u001b[1;36m1\u001b[0m.\n",
       "        \u001b[33mweight_neg\u001b[0m=\u001b[1;36m1\u001b[0m.\n",
       "      \u001b[1m)\u001b[0m\n",
       "      \u001b[33ml2\u001b[0m=\u001b[1;36m0\u001b[0m.\n",
       "      \u001b[33ml1\u001b[0m=\u001b[1;36m0\u001b[0m.\n",
       "      \u001b[33mintercept_init\u001b[0m=\u001b[1;36m0\u001b[0m.\n",
       "      \u001b[33mintercept_lr\u001b[0m=\u001b[35mConstant\u001b[0m \u001b[1m(\u001b[0m\n",
       "        \u001b[33mlearning_rate\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.01\u001b[0m\n",
       "      \u001b[1m)\u001b[0m\n",
       "      \u001b[33mclip_gradient\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m+12\u001b[0m\n",
       "      \u001b[33minitializer\u001b[0m=\u001b[35mZeros\u001b[0m \u001b[1m(\u001b[0m\u001b[1m)\u001b[0m\n",
       "    \u001b[1m)\u001b[0m\n",
       "    \u001b[33mdesired_dist\u001b[0m=\u001b[1m{\u001b[0m\u001b[1;36m0\u001b[0m: \u001b[1;36m0.5\u001b[0m, \u001b[1;36m1\u001b[0m: \u001b[1;36m0.5\u001b[0m\u001b[1m}\u001b[0m\n",
       "    \u001b[33mseed\u001b[0m=\u001b[1;36m42\u001b[0m\n",
       "  \u001b[1m)\u001b[0m\n",
       "\u001b[1m)\u001b[0m"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results of the logistic regression are quite good but still inferior to the naive Bayes model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try to use word embeddings to improve our logistic regression. Word embeddings allow you to represent a word as a vector. Embeddings are developed to build semantically rich vectors. For instance, the vector which represents the word **python** should be close to the vector which represents the word **programming**. We will use [spaCy](https://spacy.io/) to convert our sentence to vectors. spaCy converts a sentence to a vector by calculating the average of the embeddings of the words in the sentence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can download pre-trained embeddings in many languages. We will use English pre-trained embeddings as our SMS are in English."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The command below allows you to download the pre-trained embeddings that spaCy makes available. More informations about spaCy and its installation may be found here [here](https://spacy.io/usage)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```sh\n",
    "python -m spacy download en_core_web_sm\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we create a custom transformer to convert an input sentence to a dict of floats. We will integrate this transformer into our pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-24T18:24:11.798266Z",
     "iopub.status.busy": "2024-11-24T18:24:11.798088Z",
     "iopub.status.idle": "2024-11-24T18:24:12.364332Z",
     "shell.execute_reply": "2024-11-24T18:24:12.363682Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "from river.base import Transformer\n",
    "\n",
    "class Embeddings(Transformer):\n",
    "    \"\"\"My custom transformer, word embedding using spaCy.\"\"\"\n",
    "    \n",
    "    def __init__(self, on: str):\n",
    "        self.on = on\n",
    "        self.embeddings = spacy.load('en_core_web_sm')\n",
    "        \n",
    "    def transform_one(self, x, y=None):\n",
    "        return {dimension: xi for dimension, xi in enumerate(self.embeddings(x[self.on]).vector)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's train our logistic regression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-24T18:24:12.366519Z",
     "iopub.status.busy": "2024-11-24T18:24:12.366219Z",
     "iopub.status.idle": "2024-11-24T18:25:08.569875Z",
     "shell.execute_reply": "2024-11-24T18:25:08.569315Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "ROCAUC: \u001b[1;36m91.86\u001b[0m%"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_y = datasets.SMSSpam()\n",
    "\n",
    "model = (\n",
    "    Embeddings(on='body') | \n",
    "    preprocessing.Normalizer() |\n",
    "    imblearn.RandomOverSampler(\n",
    "        classifier=linear_model.LogisticRegression(\n",
    "            optimizer=optim.SGD(.5), \n",
    "            loss=optim.losses.Log()\n",
    "        ),\n",
    "        desired_dist={0: .5, 1: .5},\n",
    "        seed=42\n",
    "    )\n",
    ")\n",
    "\n",
    "metric = metrics.ROCAUC()\n",
    "cm = metrics.ConfusionMatrix()\n",
    "\n",
    "for x, y in X_y:\n",
    "    \n",
    "    y_pred = model.predict_one(x)\n",
    "    \n",
    "    metric.update(y_pred=y_pred, y_true=y)\n",
    "    cm.update(y_pred=y_pred, y_true=y)\n",
    "    \n",
    "    model.learn_one(x, y)\n",
    "\n",
    "metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The confusion matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-24T18:25:08.571961Z",
     "iopub.status.busy": "2024-11-24T18:25:08.571573Z",
     "iopub.status.idle": "2024-11-24T18:25:08.576990Z",
     "shell.execute_reply": "2024-11-24T18:25:08.576536Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "        \u001b[3;91mFalse\u001b[0m   \u001b[3;92mTrue\u001b[0m  \n",
       "\u001b[3;91mFalse\u001b[0m   \u001b[1;36m4\u001b[0m,\u001b[1;36m545\u001b[0m    \u001b[1;36m282\u001b[0m  \n",
       " \u001b[3;92mTrue\u001b[0m      \u001b[1;36m78\u001b[0m    \u001b[1;36m669\u001b[0m  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-24T18:25:08.578883Z",
     "iopub.status.busy": "2024-11-24T18:25:08.578437Z",
     "iopub.status.idle": "2024-11-24T18:25:08.587278Z",
     "shell.execute_reply": "2024-11-24T18:25:08.586665Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div><div class=\"river-component river-pipeline\"><details class=\"river-component river-estimator\"><summary class=\"river-summary\"><pre class=\"river-estimator-name\">Embeddings</pre></summary><code class=\"river-estimator-params\">Embeddings (\n",
       "  on=\"body\"\n",
       ")\n",
       "</code></details><details class=\"river-component river-estimator\"><summary class=\"river-summary\"><pre class=\"river-estimator-name\">Normalizer</pre></summary><code class=\"river-estimator-params\">Normalizer (\n",
       "  order=2\n",
       ")\n",
       "</code></details><div class=\"river-component river-wrapper\"><details class=\"river-details\"><summary class=\"river-summary\"><pre class=\"river-estimator-name\">RandomOverSampler</pre></summary><code class=\"river-estimator-params\">RandomOverSampler (\n",
       "  classifier=LogisticRegression (\n",
       "    optimizer=SGD (\n",
       "      lr=Constant (\n",
       "        learning_rate=0.5\n",
       "      )\n",
       "    )\n",
       "    loss=Log (\n",
       "      weight_pos=1.\n",
       "      weight_neg=1.\n",
       "    )\n",
       "    l2=0.\n",
       "    l1=0.\n",
       "    intercept_init=0.\n",
       "    intercept_lr=Constant (\n",
       "      learning_rate=0.01\n",
       "    )\n",
       "    clip_gradient=1e+12\n",
       "    initializer=Zeros ()\n",
       "  )\n",
       "  desired_dist={0: 0.5, 1: 0.5}\n",
       "  seed=42\n",
       ")\n",
       "</code></details><details class=\"river-component river-estimator\"><summary class=\"river-summary\"><pre class=\"river-estimator-name\">LogisticRegression</pre></summary><code class=\"river-estimator-params\">LogisticRegression (\n",
       "  optimizer=SGD (\n",
       "    lr=Constant (\n",
       "      learning_rate=0.5\n",
       "    )\n",
       "  )\n",
       "  loss=Log (\n",
       "    weight_pos=1.\n",
       "    weight_neg=1.\n",
       "  )\n",
       "  l2=0.\n",
       "  l1=0.\n",
       "  intercept_init=0.\n",
       "  intercept_lr=Constant (\n",
       "    learning_rate=0.01\n",
       "  )\n",
       "  clip_gradient=1e+12\n",
       "  initializer=Zeros ()\n",
       ")\n",
       "</code></details></div></div><style scoped>\n",
       ".river-estimator {\n",
       "    padding: 1em;\n",
       "    border-style: solid;\n",
       "    background: white;\n",
       "    max-width: max-content;\n",
       "}\n",
       "\n",
       ".river-pipeline {\n",
       "    display: flex;\n",
       "    flex-direction: column;\n",
       "    align-items: center;\n",
       "    background: linear-gradient(#000, #000) no-repeat center / 1.5px 100%;\n",
       "}\n",
       "\n",
       ".river-union {\n",
       "    display: flex;\n",
       "    flex-direction: row;\n",
       "    align-items: center;\n",
       "    justify-content: center;\n",
       "    padding: 1em;\n",
       "    border-style: solid;\n",
       "    background: white;\n",
       "}\n",
       "\n",
       ".river-wrapper {\n",
       "    display: flex;\n",
       "    flex-direction: column;\n",
       "    align-items: center;\n",
       "    justify-content: center;\n",
       "    padding: 1em;\n",
       "    border-style: solid;\n",
       "    background: white;\n",
       "}\n",
       "\n",
       ".river-wrapper > .river-estimator {\n",
       "    margin-top: 1em;\n",
       "}\n",
       "\n",
       "/* Vertical spacing between steps */\n",
       "\n",
       ".river-component + .river-component {\n",
       "    margin-top: 2em;\n",
       "}\n",
       "\n",
       ".river-union > .river-estimator {\n",
       "    margin-top: 0;\n",
       "}\n",
       "\n",
       ".river-union > .river-component {\n",
       "    margin-top: 0;\n",
       "}\n",
       "\n",
       ".river-union > .pipeline {\n",
       "    margin-top: 0;\n",
       "}\n",
       "\n",
       "/* Spacing within a union of estimators */\n",
       "\n",
       ".river-union > .river-component + .river-component {\n",
       "    margin-left: 1em;\n",
       "}\n",
       "\n",
       "/* Typography */\n",
       "\n",
       ".river-estimator-params {\n",
       "    display: block;\n",
       "    white-space: pre-wrap;\n",
       "    font-size: 110%;\n",
       "    margin-top: 1em;\n",
       "}\n",
       "\n",
       ".river-estimator > .river-estimator-params,\n",
       ".river-wrapper > .river-details > river-estimator-params {\n",
       "    background-color: white !important;\n",
       "}\n",
       "\n",
       ".river-wrapper > .river-details {\n",
       "    margin-bottom: 1em;\n",
       "}\n",
       "\n",
       ".river-estimator-name {\n",
       "    display: inline;\n",
       "    margin: 0;\n",
       "    font-size: 110%;\n",
       "}\n",
       "\n",
       "/* Toggle */\n",
       "\n",
       ".river-summary {\n",
       "    display: flex;\n",
       "    align-items:center;\n",
       "    cursor: pointer;\n",
       "}\n",
       "\n",
       ".river-summary > div {\n",
       "    width: 100%;\n",
       "}\n",
       "</style></div>"
      ],
      "text/plain": [
       "\n",
       "Pipeline \u001b[1m(\u001b[0m\n",
       "  Embeddings \u001b[1m(\u001b[0m\n",
       "    \u001b[33mon\u001b[0m=\u001b[32m\"body\"\u001b[0m\n",
       "  \u001b[1m)\u001b[0m,\n",
       "  Normalizer \u001b[1m(\u001b[0m\n",
       "    \u001b[33morder\u001b[0m=\u001b[1;36m2\u001b[0m\n",
       "  \u001b[1m)\u001b[0m,\n",
       "  RandomOverSampler \u001b[1m(\u001b[0m\n",
       "    \u001b[33mclassifier\u001b[0m=\u001b[35mLogisticRegression\u001b[0m \u001b[1m(\u001b[0m\n",
       "      \u001b[33moptimizer\u001b[0m=\u001b[35mSGD\u001b[0m \u001b[1m(\u001b[0m\n",
       "        \u001b[33mlr\u001b[0m=\u001b[35mConstant\u001b[0m \u001b[1m(\u001b[0m\n",
       "          \u001b[33mlearning_rate\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.5\u001b[0m\n",
       "        \u001b[1m)\u001b[0m\n",
       "      \u001b[1m)\u001b[0m\n",
       "      \u001b[33mloss\u001b[0m=\u001b[35mLog\u001b[0m \u001b[1m(\u001b[0m\n",
       "        \u001b[33mweight_pos\u001b[0m=\u001b[1;36m1\u001b[0m.\n",
       "        \u001b[33mweight_neg\u001b[0m=\u001b[1;36m1\u001b[0m.\n",
       "      \u001b[1m)\u001b[0m\n",
       "      \u001b[33ml2\u001b[0m=\u001b[1;36m0\u001b[0m.\n",
       "      \u001b[33ml1\u001b[0m=\u001b[1;36m0\u001b[0m.\n",
       "      \u001b[33mintercept_init\u001b[0m=\u001b[1;36m0\u001b[0m.\n",
       "      \u001b[33mintercept_lr\u001b[0m=\u001b[35mConstant\u001b[0m \u001b[1m(\u001b[0m\n",
       "        \u001b[33mlearning_rate\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.01\u001b[0m\n",
       "      \u001b[1m)\u001b[0m\n",
       "      \u001b[33mclip_gradient\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m+12\u001b[0m\n",
       "      \u001b[33minitializer\u001b[0m=\u001b[35mZeros\u001b[0m \u001b[1m(\u001b[0m\u001b[1m)\u001b[0m\n",
       "    \u001b[1m)\u001b[0m\n",
       "    \u001b[33mdesired_dist\u001b[0m=\u001b[1m{\u001b[0m\u001b[1;36m0\u001b[0m: \u001b[1;36m0.5\u001b[0m, \u001b[1;36m1\u001b[0m: \u001b[1;36m0.5\u001b[0m\u001b[1m}\u001b[0m\n",
       "    \u001b[33mseed\u001b[0m=\u001b[1;36m42\u001b[0m\n",
       "  \u001b[1m)\u001b[0m\n",
       "\u001b[1m)\u001b[0m"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results of the logistic regression using spaCy embeddings are lower than those obtained with TF-IDF values. We could surely improve the results by cleaning up the text. We could also use embeddings more suited to our dataset. However, on this problem, the logistic regression is not better than the Naive Bayes model. No free lunch today."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "14b46bd212fa4dd89e3980db6ba7efbb9fe535833e1e483b914b71733e0a56d2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
